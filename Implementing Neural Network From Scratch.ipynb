{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tg9fRSjFtsRu"
   },
   "source": [
    "\n",
    "##  Implementing Neural Network From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjsZpx5C9eBH"
   },
   "source": [
    "More often than not, we will use a deep learning library (Tensorflow, Pytorch, or the wrapper known as Keras) to implement our models. However, the abstraction afforded by those libraries can make it hard to troubleshoot issues if we don't understand what is going on under the hood. Here I will implement a fully-connected.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NzW9M-btzqO"
   },
   "source": [
    "Implementing a fully-connected neural network from scratch. The neural network will have the following architecture:\n",
    "\n",
    "- Input layer\n",
    "- Dense hidden layer with 512 neurons, using relu as the activation function\n",
    "- Dropout with a value of 0.2\n",
    "- Dense hidden layer with 512 neurons, using relu as the activation function\n",
    "- Dropout with a value of 0.2\n",
    "- Output layer, using softmax as the activation function\n",
    "\n",
    "The model will use categorical crossentropy as its loss function. \n",
    "We will optimize the gradient descent using RMSProp, with a learning rate of 0.001 and a rho value of 0.9.\n",
    "We will evaluate the model using accuracy.\n",
    "\n",
    "Why this architecture? We are trying to reproduce from scratch the following [example from the Keras documentation](https://keras.io/examples/mnist_mlp/). This means that you can compare your results by running the Keras code provided above to see if you are on the right track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rPUmRqBtpS2"
   },
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "import numpy as np\n",
    "import sklearn.metrics as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def relu(X): \n",
    "         #https://medium.com/aiÂ³-theory-practice-business/a-beginners-guide-to-numpy-with-sigmoid-relu-and-softmax-activation-functions-25b840a9a272\n",
    "        return np.maximum(0,X)\n",
    "\n",
    "def relu_Derivative(X):\n",
    "    for i in range(0,X.shape[0],1):\n",
    "        for j in range(0,X.shape[1],1):\n",
    "            if X[i][j]>0:\n",
    "                X[i][j] =1\n",
    "            else:\n",
    "                X[i][j]=0\n",
    "    return X            \n",
    "            \n",
    "    \n",
    "    \n",
    "def softmax(X):\n",
    "     \n",
    "    for i in range(0,len(X),1):\n",
    "        x_max=max(X[i])\n",
    "        for j in range(0,len(X[i]),1):\n",
    "            X[i][j]=X[i][j]-x_max #Normalization: https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python\n",
    "    Exp=np.exp(X)\n",
    "    for i in range(0,len(X),1):\n",
    "        expo_sum = np.sum(Exp[i])\n",
    "        for j in range(0,len(X[i]),1):\n",
    "            Exp[i][j]=Exp[i][j]/expo_sum\n",
    "        expo_sum=0\n",
    "    return Exp \n",
    "\n",
    "\n",
    "\n",
    "def drop_out_mask(X,drop_out):\n",
    "    a=[0,1]\n",
    "    mask=np.random.choice(a, X.shape,p=[drop_out,1-drop_out])\n",
    "    return mask*X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def RMS_prop(V_dq,V_db,Q,B,Grad_Q,Grad_B,learning_rate,rho):\n",
    "    #referred =https://gluon.mxnet.io/chapter06_optimization/rmsprop-scratch.html\n",
    "    \n",
    "    eps = 1e-8                       \n",
    "    V_dq=rho*V_dq+(1-rho)*(np.multiply(Grad_Q,Grad_Q))\n",
    "    V_db=rho*V_db+(1-rho)*(np.multiply(Grad_B,Grad_B))\n",
    "\n",
    "    \n",
    "    Q=Q-(learning_rate*(Grad_Q/np.sqrt( V_dq + eps)))\n",
    "    B=B-(learning_rate*(Grad_B/np.sqrt( V_db + eps)))\n",
    "    \n",
    "    return V_dq,V_db,Q,B\n",
    "\n",
    "            \n",
    "def evaluate(Pred,Obsrv):#https://beckernick.github.io/neural-network-scratch/\n",
    "    \n",
    "\n",
    "    Pred=np.argmax(Pred, 1)\n",
    "    preds_correct =  Pred == np.argmax(Obsrv,1)\n",
    "    correct_predictions = np.sum(preds_correct)\n",
    "    accuracy = 100.0 * correct_predictions / Pred.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "  def __init__(self,epochs, learning_rate):\n",
    "    \n",
    "    self.epochs=epochs\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "  def feed_forward(self,X,Y,Q1,Q2,Q3,B1,B2,B3,drop_out):\n",
    "        \n",
    "\n",
    "    #Layer 1\n",
    "        Z1=Q1.dot(X)+B1\n",
    "        A1=relu(Z1)\n",
    "        A1=drop_out_mask(A1,drop_out)\n",
    "\n",
    "    #Layer 2\n",
    "        Z2=(Q2).dot(A1)+B2\n",
    "        A2=relu(Z2)\n",
    "        A2=drop_out_mask(A2,drop_out)\n",
    "\n",
    "    #Layer 3\n",
    "        Z3=(Q3).dot(A2)+B3\n",
    "        A3=softmax(Z3.T)\n",
    "        \n",
    "\n",
    "        return A1,A2,A3,Z1,Z2,Z3\n",
    "        \n",
    "  def back_prop(self,Q1,Q2,Q3,B1,B2,B3,A1,A2,A3,Z1,Z2,Z3,X,Y):\n",
    "\n",
    "        \n",
    "        #error at layer 3(output) \n",
    "        Err3=(A3-Y).T # Formula reference: https://peterroelants.github.io/posts/cross-entropy-softmax/\n",
    "        \n",
    "        #error at layer 2\n",
    "        Err2=np.multiply(Q3.T.dot(Err3),relu_Derivative(Z2))\n",
    "        \n",
    "        #error at layer 1\n",
    "        Err1=np.multiply(Q2.T.dot(Err2),relu_Derivative(Z1))\n",
    "    \n",
    "        ##Computing weight gradients for layer3 (Output)\n",
    "        Q3_Grad=(Err3.dot(A2.T))/(X.shape[1])\n",
    "        B3_Grad=Err3.sum(axis=1).reshape(len(B3),1)/(X.shape[1])\n",
    "        \n",
    "        ##Computing weight gradients for layer3 (Output)\n",
    "        Q2_Grad=(Err2.dot(A1.T))/(X.shape[1])\n",
    "        B2_Grad=Err2.sum(axis=1).reshape(len(B2),1)/(X.shape[1])\n",
    "        \n",
    "        ##Computing weight gradients for layer3 (Output)\n",
    "        Q1_Grad=(Err1.dot(X.T))/(X.shape[1])\n",
    "        B1_Grad=(Err1.sum(axis=1).reshape(len(B1),1)/(X.shape[1]))\n",
    "\n",
    "        \n",
    "        \n",
    "        return Q1_Grad,Q2_Grad,Q3_Grad,B1_Grad,B2_Grad,B3_Grad\n",
    "    \n",
    "        \n",
    "              \n",
    "  \n",
    "  def fit(self,X,Y,drop_out,batch_num,x_test=None,y_test=None):\n",
    "        batch_size=500\n",
    "        #layer size\n",
    "        neu=512\n",
    "        X_data=X\n",
    "        Y_data=Y\n",
    "        X=X[:,:batch_size]\n",
    "        Y=Y[:batch_size,:]\n",
    "        \n",
    "        # He Weight Initialize randomization \n",
    "        #Reference:https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528\n",
    "        Q1=np.random.randn(neu,X.shape[0])*np.sqrt(2/X.shape[0]) # 512*60000\n",
    "        Q2=np.random.randn(neu,neu)*np.sqrt(2/neu)# 512* 512\n",
    "        Q3=np.random.randn(Y[0].shape[0],neu)*np.sqrt(2/neu)# 10*512\n",
    "        \n",
    "        #Bias Initialization with near zero\n",
    "        B1=np.ones((Q1.shape[0],1))*0.01 \n",
    "        B2=np.ones((Q2.shape[0],1))*0.01\n",
    "        B3=np.ones((Q3.shape[0],1))*0.01\n",
    "\n",
    "        \n",
    "        #inintialize for rms prop\n",
    "        V_dq1=np.zeros((Q1.shape))\n",
    "        V_dq2=np.zeros((Q2.shape))\n",
    "        V_dq3=np.zeros((Q3.shape))\n",
    "        V_db1=np.zeros((B1.shape))\n",
    "        V_db2=np.zeros((B2.shape))\n",
    "        V_db3=np.zeros((B3.shape))\n",
    "        \n",
    "        #epoch\n",
    "        for j in range(0,self.epochs,1):\n",
    "            print(\"epoch\"+str(j))\n",
    "\n",
    "            for i in range(0,batch_num,1):\n",
    "\n",
    "                X=X_data[:,i*batch_size:(i*batch_size)+batch_size]\n",
    "                Y=Y_data[i*batch_size:(i*batch_size)+batch_size,:]\n",
    "               \n",
    "                \n",
    "                #Feed Forward\n",
    "                A1,A2,A3,Z1,Z2,Z3=self.feed_forward(X,Y,Q1,Q2,Q3,B1,B2,B3,drop_out)\n",
    "\n",
    "                \n",
    "                #Back Prop\n",
    "                Q1_Grad,Q2_Grad,Q3_Grad,B1_Grad,B2_Grad,B3_Grad=self.back_prop(Q1,Q2,Q3,B1,B2,B3,A1,A2,A3,Z1,Z2,Z3,X,Y)\n",
    "               \n",
    "    \n",
    "    \n",
    "                #RMS Prop\n",
    "    \n",
    "                V_dq1,V_db1,Q1,B1=RMS_prop(V_dq1,V_db1,Q1,B1,Q1_Grad,B1_Grad,0.001,0.9)\n",
    "                V_dq2,V_db2,Q2,B2=RMS_prop(V_dq2,V_db2,Q2,B2,Q2_Grad,B2_Grad,0.001,0.9)\n",
    "                V_dq3,V_db3,Q3,b3=RMS_prop(V_dq3,V_db3,Q3,B3,Q3_Grad,B3_Grad,0.001,0.9)\n",
    "            \n",
    "            if x_test is not None:\n",
    "                \n",
    "                A1_train,A2_train,A3_train,Z1_train,Z2_train,Z3_train=self.feed_forward(X_data,Y_data,Q1,Q2,Q3,B1,B2,B3,drop_out)   \n",
    "                Score_train=evaluate(Y_data, A3_train)\n",
    "                \n",
    "                # loss func\n",
    "                Tot_Loss=0\n",
    "                for i in range(0,X_data.shape[1],1):\n",
    "                    Loss_func=-(np.log(A3_train[i]).dot(Y_data[i].T))\n",
    "                    Tot_Loss=Tot_Loss+Loss_func\n",
    "\n",
    "                Loss.append(Tot_Loss/X_data.shape[1]) \n",
    "                Iteration.append(j)\n",
    "                \n",
    "                A1_test,A2_test,A3_test,Z1_test,Z2_test,Z3_test=self.feed_forward(x_test,y_test,Q1,Q2,Q3,B1,B2,B3,drop_out)\n",
    "                Score_test=evaluate(y_test, A3_test)\n",
    "                print(\"Train accuracy :\"+str(Score_train)+\" Loss :\"+str(Tot_Loss/X_data.shape[1])+\" Test accuracy :\"+str(Score_test))\n",
    "            else:\n",
    "                \n",
    "                #Evaluate\n",
    "                Score=evaluate(Y, A3)\n",
    "                print(\"accuracy\"+str(Score))\n",
    "    \n",
    "    \n",
    "\n",
    "        return Q1,Q2,Q3,B1,B2,B3,A1,A2,A3\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH3bgJyPuE2O"
   },
   "source": [
    "Train your fully-connected neural network on the Fashion-MNIST dataset using 5-fold cross validation. Report accuracy on the folds, as well as on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsN4sUoUugl8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "784\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# To simplify the usage of our dataset, we will be importing it from the Keras \n",
    "# library. Keras can be installed using pip: python -m pip install keras\n",
    "\n",
    "# Original source for the dataset:\n",
    "# https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "# Reference to the Fashion-MNIST's Keras function: \n",
    "# https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "import keras\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# each sample is 28* 28 matrix\n",
    "#print(x_train[0])\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(x_train[0].shape[0])\n",
    "print(y_train[0])\n",
    "\n",
    "X=x_train.T\n",
    "Y=y_train\n",
    "x_test=x_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########Cross Validation Set: 0###############\n",
      "epoch0\n",
      "accuracy76.0\n",
      "epoch1\n",
      "accuracy80.2\n",
      "epoch2\n",
      "accuracy81.8\n",
      "epoch3\n",
      "accuracy82.4\n",
      "epoch4\n",
      "accuracy83.4\n",
      "epoch5\n",
      "accuracy83.4\n",
      "epoch6\n",
      "accuracy85.4\n",
      "epoch7\n",
      "accuracy84.8\n",
      "epoch8\n",
      "accuracy87.2\n",
      "epoch9\n",
      "accuracy87.8\n",
      "epoch10\n",
      "accuracy87.2\n",
      "epoch11\n",
      "accuracy87.4\n",
      "epoch12\n",
      "accuracy88.2\n",
      "epoch13\n",
      "accuracy88.2\n",
      "epoch14\n",
      "accuracy87.6\n",
      "epoch15\n",
      "accuracy88.6\n",
      "epoch16\n",
      "accuracy90.4\n",
      "epoch17\n",
      "accuracy88.6\n",
      "epoch18\n",
      "accuracy90.2\n",
      "epoch19\n",
      "accuracy89.8\n",
      "Train Score :91.8875\n",
      "Valid_score :88.89166666666667\n",
      "Test_score :88.05\n",
      "###########Cross Validation Set: 1###############\n",
      "epoch0\n",
      "accuracy77.4\n",
      "epoch1\n",
      "accuracy83.0\n",
      "epoch2\n",
      "accuracy82.6\n",
      "epoch3\n",
      "accuracy82.2\n",
      "epoch4\n",
      "accuracy83.6\n",
      "epoch5\n",
      "accuracy86.0\n",
      "epoch6\n",
      "accuracy83.6\n",
      "epoch7\n",
      "accuracy87.6\n",
      "epoch8\n",
      "accuracy85.6\n",
      "epoch9\n",
      "accuracy87.8\n",
      "epoch10\n",
      "accuracy87.4\n",
      "epoch11\n",
      "accuracy88.6\n",
      "epoch12\n",
      "accuracy86.0\n",
      "epoch13\n",
      "accuracy89.2\n",
      "epoch14\n",
      "accuracy89.4\n",
      "epoch15\n",
      "accuracy88.2\n",
      "epoch16\n",
      "accuracy91.0\n",
      "epoch17\n",
      "accuracy90.0\n",
      "epoch18\n",
      "accuracy91.0\n",
      "epoch19\n",
      "accuracy90.8\n",
      "Train Score :92.72708333333334\n",
      "Valid_score :89.33333333333333\n",
      "Test_score :88.66\n",
      "###########Cross Validation Set: 2###############\n",
      "epoch0\n",
      "accuracy73.6\n",
      "epoch1\n",
      "accuracy78.4\n",
      "epoch2\n",
      "accuracy81.6\n",
      "epoch3\n",
      "accuracy79.4\n",
      "epoch4\n",
      "accuracy82.2\n",
      "epoch5\n",
      "accuracy83.8\n",
      "epoch6\n",
      "accuracy84.8\n",
      "epoch7\n",
      "accuracy86.2\n",
      "epoch8\n",
      "accuracy85.8\n",
      "epoch9\n",
      "accuracy85.8\n",
      "epoch10\n",
      "accuracy84.0\n",
      "epoch11\n",
      "accuracy86.8\n",
      "epoch12\n",
      "accuracy88.0\n",
      "epoch13\n",
      "accuracy87.0\n",
      "epoch14\n",
      "accuracy87.4\n",
      "epoch15\n",
      "accuracy87.4\n",
      "epoch16\n",
      "accuracy87.4\n",
      "epoch17\n",
      "accuracy88.0\n",
      "epoch18\n",
      "accuracy90.0\n",
      "epoch19\n",
      "accuracy90.2\n",
      "Train Score :93.25416666666666\n",
      "Valid_score :90.03333333333333\n",
      "Test_score :89.09\n",
      "###########Cross Validation Set: 3###############\n",
      "epoch0\n",
      "accuracy79.2\n",
      "epoch1\n",
      "accuracy81.6\n",
      "epoch2\n",
      "accuracy79.2\n",
      "epoch3\n",
      "accuracy84.2\n",
      "epoch4\n",
      "accuracy84.2\n",
      "epoch5\n",
      "accuracy83.0\n",
      "epoch6\n",
      "accuracy83.0\n",
      "epoch7\n",
      "accuracy86.4\n",
      "epoch8\n",
      "accuracy85.6\n",
      "epoch9\n",
      "accuracy85.6\n",
      "epoch10\n",
      "accuracy88.0\n",
      "epoch11\n",
      "accuracy87.2\n",
      "epoch12\n",
      "accuracy89.0\n",
      "epoch13\n",
      "accuracy89.8\n",
      "epoch14\n",
      "accuracy87.2\n",
      "epoch15\n",
      "accuracy89.8\n",
      "epoch16\n",
      "accuracy87.8\n",
      "epoch17\n",
      "accuracy88.4\n",
      "epoch18\n",
      "accuracy90.2\n",
      "epoch19\n",
      "accuracy89.6\n",
      "Train Score :92.075\n",
      "Valid_score :89.30833333333334\n",
      "Test_score :88.22\n",
      "###########Cross Validation Set: 4###############\n",
      "epoch0\n",
      "accuracy80.0\n",
      "epoch1\n",
      "accuracy85.6\n",
      "epoch2\n",
      "accuracy88.2\n",
      "epoch3\n",
      "accuracy87.0\n",
      "epoch4\n",
      "accuracy89.4\n",
      "epoch5\n",
      "accuracy89.0\n",
      "epoch6\n",
      "accuracy89.4\n",
      "epoch7\n",
      "accuracy90.4\n",
      "epoch8\n",
      "accuracy89.0\n",
      "epoch9\n",
      "accuracy89.2\n",
      "epoch10\n",
      "accuracy88.4\n",
      "epoch11\n",
      "accuracy91.0\n",
      "epoch12\n",
      "accuracy90.0\n",
      "epoch13\n",
      "accuracy92.2\n",
      "epoch14\n",
      "accuracy90.2\n",
      "epoch15\n",
      "accuracy91.2\n",
      "epoch16\n",
      "accuracy91.4\n",
      "epoch17\n",
      "accuracy91.0\n",
      "epoch18\n",
      "accuracy93.4\n",
      "epoch19\n",
      "accuracy92.4\n",
      "Train Score :92.83541666666666\n",
      "Valid_score :89.29166666666667\n",
      "Test_score :88.86\n",
      "Training Score for 5 fold [91.8875, 92.72708333333334, 93.25416666666666, 92.075, 92.83541666666666]\n",
      "Validation Score for 5 fold [88.89166666666667, 89.33333333333333, 90.03333333333333, 89.30833333333334, 89.29166666666667]\n",
      "Testing score for 5 fold [88.05, 88.66, 89.09, 88.22, 88.86]\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "def valid_part(X,fold,k):\n",
    "    n=X.shape[1]\n",
    "    i=int((n/k)*fold)\n",
    "    j=int((n/k)*(fold+1))\n",
    "    Valid_set=X[:,i:j]\n",
    "    Train_set= (np.concatenate((X[:,:i].T, X[:,j:].T))).T\n",
    "    return Valid_set,Train_set\n",
    "    \n",
    "Loss=[]\n",
    "Iteration=[]\n",
    "Train_score=[]\n",
    "Valid_score=[]\n",
    "Test_score=[]\n",
    "def cross_validation(X,Y):\n",
    "    for fold in range(0,5,1):\n",
    "        print(\"###########Cross Validation Set: \"+str(fold)+\"###############\")\n",
    "        Valid_set,Train_set=valid_part(X,fold,5)\n",
    "        Valid_label,Train_label=valid_part(Y.T,fold,5)\n",
    "        Model=NeuralNetwork(20,1)\n",
    "        batch_num=int(Train_set.shape[1]/500)\n",
    "        Q1,Q2,Q3,B1,B2,B3,A1,A2,A3=Model.fit(Train_set,Train_label.T,0.2,batch_num)\n",
    "        A1,A2,A3,Z1,Z2,Z3=Model.feed_forward(Train_set,Train_set.T,Q1,Q2,Q3,B1,B2,B3,0)\n",
    "        Tr_score=evaluate(Train_label.T,A3)\n",
    "        Train_score.append(Tr_score)\n",
    "        A1,A2,A3,Z1,Z2,Z3=Model.feed_forward(Valid_set,Valid_label.T,Q1,Q2,Q3,B1,B2,B3,0)\n",
    "        V_score=evaluate(Valid_label.T,A3)\n",
    "        Valid_score.append(V_score)\n",
    "        print(\"Train Score :\"+str(Tr_score))\n",
    "        print(\"Valid_score :\"+str(V_score))\n",
    "        A1_test,A2_test,A3_test,Z1_test,Z2_test,Z3_test=Model.feed_forward(x_test,y_test,Q1,Q2,Q3,B1,B2,B3,0)\n",
    "        Score_test=evaluate(y_test, A3_test)\n",
    "        print(\"Test_score :\"+str(Score_test))\n",
    "        Test_score.append(Score_test)\n",
    "        \n",
    "    print(\"Training Score for 5 fold \"+str(Train_score))\n",
    "    print(\"Validation Score for 5 fold \"+str(Valid_score))\n",
    "    print(\"Testing score for 5 fold \"+str(Test_score))\n",
    "        \n",
    "        \n",
    "#Cross validation\n",
    "cross_validation(X,Y)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0\n",
      "Train accuracy :79.54666666666667 Loss :0.5431707898507998 Test accuracy :78.36\n",
      "epoch1\n",
      "Train accuracy :81.89333333333333 Loss :0.5045496815885411 Test accuracy :80.44\n",
      "epoch2\n",
      "Train accuracy :84.79333333333334 Loss :0.3990065194805477 Test accuracy :83.32\n",
      "epoch3\n",
      "Train accuracy :84.96166666666667 Loss :0.39241004516647304 Test accuracy :83.4\n",
      "epoch4\n",
      "Train accuracy :87.53166666666667 Loss :0.32863506619528715 Test accuracy :85.42\n",
      "epoch5\n",
      "Train accuracy :87.91333333333333 Loss :0.3166613761735594 Test accuracy :85.93\n",
      "epoch6\n",
      "Train accuracy :88.18666666666667 Loss :0.31273377589069823 Test accuracy :85.89\n",
      "epoch7\n",
      "Train accuracy :88.45166666666667 Loss :0.30170864379195705 Test accuracy :86.2\n",
      "epoch8\n",
      "Train accuracy :89.965 Loss :0.2642814247335282 Test accuracy :87.13\n",
      "epoch9\n",
      "Train accuracy :89.55 Loss :0.2747081741826826 Test accuracy :86.73\n",
      "epoch10\n",
      "Train accuracy :90.285 Loss :0.252073289399758 Test accuracy :87.68\n",
      "epoch11\n",
      "Train accuracy :90.425 Loss :0.24795265389323407 Test accuracy :87.91\n",
      "epoch12\n",
      "Train accuracy :90.48833333333333 Loss :0.2467179994273734 Test accuracy :87.85\n",
      "epoch13\n",
      "Train accuracy :90.68166666666667 Loss :0.23996555363265348 Test accuracy :87.95\n",
      "epoch14\n",
      "Train accuracy :90.81333333333333 Loss :0.2379158711138638 Test accuracy :87.65\n",
      "epoch15\n",
      "Train accuracy :91.23666666666666 Loss :0.22592932251980172 Test accuracy :87.7\n",
      "epoch16\n",
      "Train accuracy :91.02833333333334 Loss :0.23096194915648488 Test accuracy :88.34\n",
      "epoch17\n",
      "Train accuracy :91.37166666666667 Loss :0.221818868129222 Test accuracy :88.12\n",
      "epoch18\n",
      "Train accuracy :91.895 Loss :0.20832826479329594 Test accuracy :88.76\n",
      "epoch19\n",
      "Train accuracy :91.79333333333334 Loss :0.2137671672878805 Test accuracy :88.12\n",
      "fit\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fitting\n",
    "Loss=[]\n",
    "Iteration=[]\n",
    "N=NeuralNetwork(20,1)\n",
    "batch_num=int(X.shape[1]/500)\n",
    "Q1,Q2,Q3,B1,B2,B3,A1,A2,A3=N.fit(X,Y,0.2,batch_num,x_test,y_test)\n",
    "print(\"fit\")\n",
    "\n",
    "#graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Iteration,Loss)\n",
    "ax.set_xlabel('No of Iteration')\n",
    "ax.set_ylabel('Loss Function')\n",
    "ax.set_title('Loss Graph')\n",
    "plt.show()\n",
    "                   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A3-P556-F19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
